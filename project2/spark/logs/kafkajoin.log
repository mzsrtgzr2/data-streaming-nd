:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-ee4b9b43-f240-41f0-84a0-a7237cf037d9;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 in central
	found org.apache.kafka#kafka-clients;2.4.1 in central
	found com.github.luben#zstd-jni;1.4.4-3 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.7.5 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
:: resolution report :: resolve 699ms :: artifacts dl 60ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.4-3 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.0.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.0.0 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.7.5 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   9   |   0   |   0   |   0   ||   9   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-ee4b9b43-f240-41f0-84a0-a7237cf037d9
	confs: [default]
	0 artifacts copied, 9 already retrieved (0kB/20ms)
21/10/10 20:42:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/10 20:42:53 INFO SparkContext: Running Spark version 3.1.2
21/10/10 20:42:54 INFO ResourceUtils: ==============================================================
21/10/10 20:42:54 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/10 20:42:54 INFO ResourceUtils: ==============================================================
21/10/10 20:42:54 INFO SparkContext: Submitted application: Job3
21/10/10 20:42:54 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/10 20:42:54 INFO ResourceProfile: Limiting resource is cpu
21/10/10 20:42:54 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/10 20:42:54 INFO SecurityManager: Changing view acls to: spark
21/10/10 20:42:54 INFO SecurityManager: Changing modify acls to: spark
21/10/10 20:42:54 INFO SecurityManager: Changing view acls groups to: 
21/10/10 20:42:54 INFO SecurityManager: Changing modify acls groups to: 
21/10/10 20:42:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(spark); groups with view permissions: Set(); users  with modify permissions: Set(spark); groups with modify permissions: Set()
21/10/10 20:42:54 INFO Utils: Successfully started service 'sparkDriver' on port 34591.
21/10/10 20:42:54 INFO SparkEnv: Registering MapOutputTracker
21/10/10 20:42:54 INFO SparkEnv: Registering BlockManagerMaster
21/10/10 20:42:54 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/10 20:42:54 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/10 20:42:54 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/10 20:42:54 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bedcfc2c-5c3c-40df-bc89-b71d8e1a6ce9
21/10/10 20:42:54 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/10/10 20:42:54 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/10 20:42:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/10 20:42:55 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://a9760481ca71:4040
21/10/10 20:42:55 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar at spark://a9760481ca71:34591/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar at spark://a9760481ca71:34591/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar at spark://a9760481ca71:34591/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://a9760481ca71:34591/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://a9760481ca71:34591/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar at spark://a9760481ca71:34591/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://a9760481ca71:34591/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar at spark://a9760481ca71:34591/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO SparkContext: Added JAR file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://a9760481ca71:34591/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
21/10/10 20:42:55 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
21/10/10 20:42:55 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.apache.kafka_kafka-clients-2.4.1.jar
21/10/10 20:42:55 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.apache.commons_commons-pool2-2.6.2.jar
21/10/10 20:42:55 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.spark-project.spark_unused-1.0.0.jar
21/10/10 20:42:55 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar at file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/com.github.luben_zstd-jni-1.4.4-3.jar
21/10/10 20:42:55 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.lz4_lz4-java-1.7.1.jar
21/10/10 20:42:55 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar at file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.xerial.snappy_snappy-java-1.1.7.5.jar
21/10/10 20:42:55 INFO SparkContext: Added file file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO Utils: Copying /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.slf4j_slf4j-api-1.7.30.jar
21/10/10 20:42:55 INFO Executor: Starting executor ID driver on host a9760481ca71
21/10/10 20:42:55 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
21/10/10 20:42:55 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO Utils: /opt/bitnami/spark/.ivy2/jars/com.github.luben_zstd-jni-1.4.4-3.jar has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/com.github.luben_zstd-jni-1.4.4-3.jar
21/10/10 20:42:55 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.xerial.snappy_snappy-java-1.1.7.5.jar
21/10/10 20:42:55 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.kafka_kafka-clients-2.4.1.jar has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.apache.kafka_kafka-clients-2.4.1.jar
21/10/10 20:42:55 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
21/10/10 20:42:55 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1633898573980
21/10/10 20:42:55 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.apache.commons_commons-pool2-2.6.2.jar
21/10/10 20:42:56 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1633898573980
21/10/10 20:42:56 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.spark-project.spark_unused-1.0.0.jar
21/10/10 20:42:56 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1633898573980
21/10/10 20:42:56 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.lz4_lz4-java-1.7.1.jar
21/10/10 20:42:56 INFO Executor: Fetching file:///opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1633898573980
21/10/10 20:42:56 INFO Utils: /opt/bitnami/spark/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.slf4j_slf4j-api-1.7.30.jar
21/10/10 20:42:56 INFO Executor: Fetching spark://a9760481ca71:34591/jars/org.apache.kafka_kafka-clients-2.4.1.jar with timestamp 1633898573980
21/10/10 20:42:56 INFO TransportClientFactory: Successfully created connection to a9760481ca71/172.19.0.4:34591 after 51 ms (0 ms spent in bootstraps)
21/10/10 20:42:56 INFO Utils: Fetching spark://a9760481ca71:34591/jars/org.apache.kafka_kafka-clients-2.4.1.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp3299075441615619469.tmp
21/10/10 20:42:56 INFO Utils: /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp3299075441615619469.tmp has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.apache.kafka_kafka-clients-2.4.1.jar
21/10/10 20:42:56 INFO Executor: Adding file:/tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.apache.kafka_kafka-clients-2.4.1.jar to class loader
21/10/10 20:42:56 INFO Executor: Fetching spark://a9760481ca71:34591/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1633898573980
21/10/10 20:42:56 INFO Utils: Fetching spark://a9760481ca71:34591/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp8985743203244570978.tmp
21/10/10 20:42:56 INFO Utils: /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp8985743203244570978.tmp has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.apache.commons_commons-pool2-2.6.2.jar
21/10/10 20:42:56 INFO Executor: Adding file:/tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.apache.commons_commons-pool2-2.6.2.jar to class loader
21/10/10 20:42:56 INFO Executor: Fetching spark://a9760481ca71:34591/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1633898573980
21/10/10 20:42:56 INFO Utils: Fetching spark://a9760481ca71:34591/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp2922923987460128122.tmp
21/10/10 20:42:56 INFO Utils: /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp2922923987460128122.tmp has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.lz4_lz4-java-1.7.1.jar
21/10/10 20:42:56 INFO Executor: Adding file:/tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.lz4_lz4-java-1.7.1.jar to class loader
21/10/10 20:42:56 INFO Executor: Fetching spark://a9760481ca71:34591/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar with timestamp 1633898573980
21/10/10 20:42:56 INFO Utils: Fetching spark://a9760481ca71:34591/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp5751489050381485651.tmp
21/10/10 20:42:56 INFO Utils: /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp5751489050381485651.tmp has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar
21/10/10 20:42:56 INFO Executor: Adding file:/tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.apache.spark_spark-sql-kafka-0-10_2.12-3.0.0.jar to class loader
21/10/10 20:42:56 INFO Executor: Fetching spark://a9760481ca71:34591/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1633898573980
21/10/10 20:42:56 INFO Utils: Fetching spark://a9760481ca71:34591/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp5003438165758335247.tmp
21/10/10 20:42:56 INFO Utils: /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp5003438165758335247.tmp has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.spark-project.spark_unused-1.0.0.jar
21/10/10 20:42:56 INFO Executor: Adding file:/tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.spark-project.spark_unused-1.0.0.jar to class loader
21/10/10 20:42:56 INFO Executor: Fetching spark://a9760481ca71:34591/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar with timestamp 1633898573980
21/10/10 20:42:56 INFO Utils: Fetching spark://a9760481ca71:34591/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp8653502846218121814.tmp
21/10/10 20:42:56 INFO Utils: /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp8653502846218121814.tmp has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar
21/10/10 20:42:56 INFO Executor: Adding file:/tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.0.0.jar to class loader
21/10/10 20:42:56 INFO Executor: Fetching spark://a9760481ca71:34591/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1633898573980
21/10/10 20:42:56 INFO Utils: Fetching spark://a9760481ca71:34591/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp3743137703007904080.tmp
21/10/10 20:42:56 INFO Utils: /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp3743137703007904080.tmp has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.slf4j_slf4j-api-1.7.30.jar
21/10/10 20:42:56 INFO Executor: Adding file:/tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.slf4j_slf4j-api-1.7.30.jar to class loader
21/10/10 20:42:56 INFO Executor: Fetching spark://a9760481ca71:34591/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar with timestamp 1633898573980
21/10/10 20:42:56 INFO Utils: Fetching spark://a9760481ca71:34591/jars/org.xerial.snappy_snappy-java-1.1.7.5.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp1116768386506331790.tmp
21/10/10 20:42:56 INFO Utils: /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp1116768386506331790.tmp has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.xerial.snappy_snappy-java-1.1.7.5.jar
21/10/10 20:42:56 INFO Executor: Adding file:/tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/org.xerial.snappy_snappy-java-1.1.7.5.jar to class loader
21/10/10 20:42:56 INFO Executor: Fetching spark://a9760481ca71:34591/jars/com.github.luben_zstd-jni-1.4.4-3.jar with timestamp 1633898573980
21/10/10 20:42:56 INFO Utils: Fetching spark://a9760481ca71:34591/jars/com.github.luben_zstd-jni-1.4.4-3.jar to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp7845238951462296579.tmp
21/10/10 20:42:56 INFO Utils: /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/fetchFileTemp7845238951462296579.tmp has been previously copied to /tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/com.github.luben_zstd-jni-1.4.4-3.jar
21/10/10 20:42:56 INFO Executor: Adding file:/tmp/spark-a6528b53-f1cb-4340-a7ff-704bbaea9383/userFiles-cc1d8d2a-1610-44de-90fd-32f47a10bdf4/com.github.luben_zstd-jni-1.4.4-3.jar to class loader
21/10/10 20:42:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46799.
21/10/10 20:42:56 INFO NettyBlockTransferService: Server created on a9760481ca71:46799
21/10/10 20:42:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/10 20:42:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, a9760481ca71, 46799, None)
21/10/10 20:42:56 INFO BlockManagerMasterEndpoint: Registering block manager a9760481ca71:46799 with 366.3 MiB RAM, BlockManagerId(driver, a9760481ca71, 46799, None)
21/10/10 20:42:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, a9760481ca71, 46799, None)
21/10/10 20:42:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, a9760481ca71, 46799, None)
21/10/10 20:42:57 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/opt/bitnami/spark/spark-warehouse').
21/10/10 20:42:57 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
21/10/10 20:43:01 WARN StreamingQueryManager: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-e88396cf-6e91-431f-b5a0-55506b472b4a. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.
-------------------------------------------
Batch: 0
-------------------------------------------
+--------------------+-----+--------------------+---------+
|            customer|score|               email|birthYear|
+--------------------+-----+--------------------+---------+
|John.Anandh@test.com| -2.0|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -3.0|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -2.5|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -3.0|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -5.0|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -5.5|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -3.5|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -2.5|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -3.0|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -2.0|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -1.5|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -2.5|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -3.5|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -3.0|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -2.0|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -2.0|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -1.5|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -1.5|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -2.0|John.Anandh@test.com|     1956|
|John.Anandh@test.com| -2.5|John.Anandh@test.com|     1956|
+--------------------+-----+--------------------+---------+
only showing top 20 rows

-------------------------------------------
Batch: 1
-------------------------------------------
+--------------------+-----+--------------------+---------+
|            customer|score|               email|birthYear|
+--------------------+-----+--------------------+---------+
|John.Anandh@test.com| -3.5|John.Anandh@test.com|     1956|
|Craig.Lincoln@tes...| -2.0|Craig.Lincoln@tes...|     1953|
|Santosh.Olson@tes...| -3.5|Santosh.Olson@tes...|     1955|
|Neeraj.Lincoln@te...| -5.0|Neeraj.Lincoln@te...|     1959|
|Gail.Habschied@te...| -2.0|Gail.Habschied@te...|     1951|
|Santosh.Anderson@...| -1.5|Santosh.Anderson@...|     1960|
| Lyn.Khatib@test.com| -3.0| Lyn.Khatib@test.com|     1954|
|Sarah.Phillips@te...| -5.0|Sarah.Phillips@te...|     1958|
+--------------------+-----+--------------------+---------+

^CTraceback (most recent call last):
  File "/home/workspace/project/starter/sparkpykafkajoin.py", line 85, in <module>
    write_stream_to_console(df_joined)
  File "/home/workspace/project/starter/utils.py", line 19, in write_stream_to_console
    .writeStream.format('console').outputMode("append")\
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/sql/streaming.py", line 101, in awaitTermination
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1303, in __call__
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1033, in send_command
  File "/opt/bitnami/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py", line 1200, in send_command
  File "/opt/bitnami/python/lib/python3.6/socket.py", line 586, in readinto
    return self._sock.recv_into(b)
  File "/opt/bitnami/spark/python/lib/pyspark.zip/pyspark/context.py", line 285, in signal_handler
KeyboardInterrupt
21/10/10 20:43:32 ERROR MicroBatchExecution: Query [id = a399a843-d2aa-4c52-bd90-9821de68a1da, runId = 5d1181de-8dfb-4fe8-9076-5ba4694a74e2] terminated with error
java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.lang.reflect.Constructor.newInstance(Constructor.java:423)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.GatewayConnection.run(GatewayConnection.java:238)
java.lang.Thread.run(Thread.java:748)

The currently active SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.lang.reflect.Constructor.newInstance(Constructor.java:423)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.GatewayConnection.run(GatewayConnection.java:238)
java.lang.Thread.run(Thread.java:748)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)
	at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1506)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.<init>(StreamingSymmetricHashJoinExec.scala:180)
	at org.apache.spark.sql.execution.streaming.StreamingSymmetricHashJoinExec.<init>(StreamingSymmetricHashJoinExec.scala:151)
	at org.apache.spark.sql.execution.SparkStrategies$StreamingJoinStrategy$.apply(SparkStrategies.scala:413)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$1(QueryPlanner.scala:63)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:93)
	at org.apache.spark.sql.execution.SparkStrategies.plan(SparkStrategies.scala:67)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$3(QueryPlanner.scala:78)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:162)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:162)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:162)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:160)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1429)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$2(QueryPlanner.scala:75)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:93)
	at org.apache.spark.sql.execution.SparkStrategies.plan(SparkStrategies.scala:67)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$3(QueryPlanner.scala:78)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:162)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:162)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:162)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:160)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1429)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$2(QueryPlanner.scala:75)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:93)
	at org.apache.spark.sql.execution.SparkStrategies.plan(SparkStrategies.scala:67)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$3(QueryPlanner.scala:78)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:162)
	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:162)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429)
	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:162)
	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:160)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1429)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$2(QueryPlanner.scala:75)
	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:93)
	at org.apache.spark.sql.execution.SparkStrategies.plan(SparkStrategies.scala:67)
	at org.apache.spark.sql.execution.QueryExecution$.createSparkPlan(QueryExecution.scala:391)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$sparkPlan$1(QueryExecution.scala:104)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:143)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:143)
	at org.apache.spark.sql.execution.QueryExecution.sparkPlan$lzycompute(QueryExecution.scala:104)
	at org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:97)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executedPlan$1(QueryExecution.scala:117)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:143)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:143)
	at org.apache.spark.sql.execution.QueryExecution.executedPlan$lzycompute(QueryExecution.scala:117)
	at org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:110)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$14(MicroBatchExecution.scala:577)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:567)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:226)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:357)
	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:355)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:194)
	at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:188)
	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:334)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:317)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:244)
